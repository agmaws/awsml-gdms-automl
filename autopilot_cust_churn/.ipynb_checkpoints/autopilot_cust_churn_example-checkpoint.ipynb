{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction using AutoML with Amazon SageMaker Autopilot\n",
    "_**Using AutoPilot to Predict Mobile Customer Departure**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "Kernel `conda_python3` works well with this notebook.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Settingup)\n",
    "1. [Autopilot Results](#Results)\n",
    "1. [Host](#Host)\n",
    "1. [Cleanup](#Cleanup)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Amazon SageMaker Autopilot is an automated machine learning (commonly referred to as AutoML) solution for tabular datasets. You can use SageMaker Autopilot in different ways: on autopilot (hence the name) or with human guidance, without code through SageMaker Studio, or using the AWS SDKs. This notebook, as a first glimpse, will use the AWS SDKs to simply create and deploy a machine learning model.\n",
    "\n",
    "Losing customers is costly for any business.  Identifying unhappy customers early on gives you a chance to offer them incentives to stay.  This notebook describes using machine learning (ML) for the automated identification of unhappy customers, also known as customer churn prediction. ML models rarely give perfect predictions though, so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.\n",
    "\n",
    "We use an example of churn that is familiar to all of us–leaving a mobile phone operator.  Seems like I can always find fault with my provider du jour! And if my provider knows that I’m thinking of leaving, it can offer timely incentives–I can always use a phone upgrade or perhaps have a new feature activated–and I might just stick around. Incentives are often much more cost effective than losing and reacquiring a customer.\n",
    "\n",
    "---\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# You can modify the following to use a bucket of your choosing\n",
    "bucket = session.default_bucket()\n",
    "prefix = \"sagemaker/autopilot-cust-churn\"\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# This is the client we will use to interact with SageMaker AutoPilot\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "#AGM Time\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "Mobile operators have historical records on which customers ultimately ended up churning and which continued using the service. We can use this historical information to construct an ML model of one mobile operator’s churn using a process called training. After training the model, we can pass the profile information of an arbitrary customer (the same profile information that we used to train the model) to the model, and have the model predict whether this customer is going to churn. Of course, we expect the model to make mistakes–after all, predicting the future is tricky business! But I’ll also show how to deal with prediction errors.\n",
    "\n",
    "The dataset we will use is synthetically generated, but indictive of the types of features you'd see in this use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the dataset to S3\n",
    "\n",
    "Before you run Autopilot on the dataset, first perform a check of the dataset to make sure that it has no obvious errors. The Autopilot process can take long time, and it's generally a good practice to inspect the dataset before you start a job. This particular dataset is small, so you can inspect it in the notebook instance itself. If you have a larger dataset that will not fit in a notebook instance memory, inspect the dataset offline using a big data analytics tool like Apache Spark. [Deequ](https://github.com/awslabs/deequ) is a library built on top of Apache Spark that can be helpful for performing checks on large datasets. Autopilot is capable of handling datasets up to 5 GB.\n",
    "\n",
    "Read the data into a Pandas data frame and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>163</td>\n",
       "      <td>806</td>\n",
       "      <td>403-2562</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>300</td>\n",
       "      <td>8.162204</td>\n",
       "      <td>3</td>\n",
       "      <td>7.579174</td>\n",
       "      <td>3.933035</td>\n",
       "      <td>4</td>\n",
       "      <td>6.508639</td>\n",
       "      <td>4.065759</td>\n",
       "      <td>100</td>\n",
       "      <td>5.111624</td>\n",
       "      <td>4.928160</td>\n",
       "      <td>6</td>\n",
       "      <td>5.673203</td>\n",
       "      <td>3</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>15</td>\n",
       "      <td>836</td>\n",
       "      <td>158-8416</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>10.018993</td>\n",
       "      <td>4</td>\n",
       "      <td>4.226289</td>\n",
       "      <td>2.325005</td>\n",
       "      <td>0</td>\n",
       "      <td>9.972592</td>\n",
       "      <td>7.141040</td>\n",
       "      <td>200</td>\n",
       "      <td>6.436188</td>\n",
       "      <td>3.221748</td>\n",
       "      <td>6</td>\n",
       "      <td>2.559749</td>\n",
       "      <td>8</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>131</td>\n",
       "      <td>777</td>\n",
       "      <td>896-6253</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>300</td>\n",
       "      <td>4.708490</td>\n",
       "      <td>3</td>\n",
       "      <td>4.768160</td>\n",
       "      <td>4.537466</td>\n",
       "      <td>3</td>\n",
       "      <td>4.566715</td>\n",
       "      <td>5.363235</td>\n",
       "      <td>100</td>\n",
       "      <td>5.142451</td>\n",
       "      <td>7.139023</td>\n",
       "      <td>2</td>\n",
       "      <td>6.254157</td>\n",
       "      <td>4</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>75</td>\n",
       "      <td>878</td>\n",
       "      <td>817-5729</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>700</td>\n",
       "      <td>1.268734</td>\n",
       "      <td>3</td>\n",
       "      <td>2.567642</td>\n",
       "      <td>2.528748</td>\n",
       "      <td>5</td>\n",
       "      <td>2.333624</td>\n",
       "      <td>3.773586</td>\n",
       "      <td>450</td>\n",
       "      <td>3.814413</td>\n",
       "      <td>2.245779</td>\n",
       "      <td>6</td>\n",
       "      <td>1.080692</td>\n",
       "      <td>6</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>146</td>\n",
       "      <td>878</td>\n",
       "      <td>450-4942</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>2.696177</td>\n",
       "      <td>3</td>\n",
       "      <td>5.908916</td>\n",
       "      <td>6.015337</td>\n",
       "      <td>3</td>\n",
       "      <td>3.670408</td>\n",
       "      <td>3.751673</td>\n",
       "      <td>250</td>\n",
       "      <td>2.796812</td>\n",
       "      <td>6.905545</td>\n",
       "      <td>4</td>\n",
       "      <td>7.134343</td>\n",
       "      <td>6</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>4</td>\n",
       "      <td>787</td>\n",
       "      <td>151-3162</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>800</td>\n",
       "      <td>10.862632</td>\n",
       "      <td>5</td>\n",
       "      <td>7.250969</td>\n",
       "      <td>6.936164</td>\n",
       "      <td>1</td>\n",
       "      <td>8.026482</td>\n",
       "      <td>4.921314</td>\n",
       "      <td>350</td>\n",
       "      <td>6.748489</td>\n",
       "      <td>4.872570</td>\n",
       "      <td>8</td>\n",
       "      <td>2.122530</td>\n",
       "      <td>9</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>140</td>\n",
       "      <td>836</td>\n",
       "      <td>351-5993</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1.581127</td>\n",
       "      <td>8</td>\n",
       "      <td>3.758307</td>\n",
       "      <td>7.377591</td>\n",
       "      <td>7</td>\n",
       "      <td>1.328827</td>\n",
       "      <td>0.939932</td>\n",
       "      <td>300</td>\n",
       "      <td>4.522661</td>\n",
       "      <td>6.938571</td>\n",
       "      <td>2</td>\n",
       "      <td>4.600473</td>\n",
       "      <td>4</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>32</td>\n",
       "      <td>836</td>\n",
       "      <td>370-3127</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>700</td>\n",
       "      <td>0.163836</td>\n",
       "      <td>5</td>\n",
       "      <td>4.243980</td>\n",
       "      <td>5.841852</td>\n",
       "      <td>3</td>\n",
       "      <td>2.340554</td>\n",
       "      <td>0.939469</td>\n",
       "      <td>450</td>\n",
       "      <td>5.157898</td>\n",
       "      <td>4.388328</td>\n",
       "      <td>7</td>\n",
       "      <td>1.060340</td>\n",
       "      <td>6</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>142</td>\n",
       "      <td>776</td>\n",
       "      <td>604-2108</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>600</td>\n",
       "      <td>2.034454</td>\n",
       "      <td>5</td>\n",
       "      <td>3.014859</td>\n",
       "      <td>4.140554</td>\n",
       "      <td>3</td>\n",
       "      <td>3.470372</td>\n",
       "      <td>6.076043</td>\n",
       "      <td>150</td>\n",
       "      <td>4.362780</td>\n",
       "      <td>7.173376</td>\n",
       "      <td>3</td>\n",
       "      <td>4.871900</td>\n",
       "      <td>7</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>141</td>\n",
       "      <td>657</td>\n",
       "      <td>294-2849</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>500</td>\n",
       "      <td>1.803907</td>\n",
       "      <td>0</td>\n",
       "      <td>5.125716</td>\n",
       "      <td>8.357508</td>\n",
       "      <td>0</td>\n",
       "      <td>2.109823</td>\n",
       "      <td>2.624299</td>\n",
       "      <td>400</td>\n",
       "      <td>3.713631</td>\n",
       "      <td>5.798783</td>\n",
       "      <td>6</td>\n",
       "      <td>5.485345</td>\n",
       "      <td>7</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "State                                                              \n",
       "PA                163        806  403-2562         no        yes   \n",
       "SC                 15        836  158-8416        yes         no   \n",
       "MO                131        777  896-6253         no        yes   \n",
       "WY                 75        878  817-5729        yes        yes   \n",
       "WY                146        878  450-4942        yes         no   \n",
       "...               ...        ...       ...        ...        ...   \n",
       "NH                  4        787  151-3162        yes        yes   \n",
       "SD                140        836  351-5993         no         no   \n",
       "SC                 32        836  370-3127         no        yes   \n",
       "MA                142        776  604-2108        yes        yes   \n",
       "AL                141        657  294-2849        yes        yes   \n",
       "\n",
       "       VMail Message   Day Mins  Day Calls  Day Charge  Eve Mins  Eve Calls  \\\n",
       "State                                                                         \n",
       "PA               300   8.162204          3    7.579174  3.933035          4   \n",
       "SC                 0  10.018993          4    4.226289  2.325005          0   \n",
       "MO               300   4.708490          3    4.768160  4.537466          3   \n",
       "WY               700   1.268734          3    2.567642  2.528748          5   \n",
       "WY                 0   2.696177          3    5.908916  6.015337          3   \n",
       "...              ...        ...        ...         ...       ...        ...   \n",
       "NH               800  10.862632          5    7.250969  6.936164          1   \n",
       "SD                 0   1.581127          8    3.758307  7.377591          7   \n",
       "SC               700   0.163836          5    4.243980  5.841852          3   \n",
       "MA               600   2.034454          5    3.014859  4.140554          3   \n",
       "AL               500   1.803907          0    5.125716  8.357508          0   \n",
       "\n",
       "       Eve Charge  Night Mins  Night Calls  Night Charge  Intl Mins  \\\n",
       "State                                                                 \n",
       "PA       6.508639    4.065759          100      5.111624   4.928160   \n",
       "SC       9.972592    7.141040          200      6.436188   3.221748   \n",
       "MO       4.566715    5.363235          100      5.142451   7.139023   \n",
       "WY       2.333624    3.773586          450      3.814413   2.245779   \n",
       "WY       3.670408    3.751673          250      2.796812   6.905545   \n",
       "...           ...         ...          ...           ...        ...   \n",
       "NH       8.026482    4.921314          350      6.748489   4.872570   \n",
       "SD       1.328827    0.939932          300      4.522661   6.938571   \n",
       "SC       2.340554    0.939469          450      5.157898   4.388328   \n",
       "MA       3.470372    6.076043          150      4.362780   7.173376   \n",
       "AL       2.109823    2.624299          400      3.713631   5.798783   \n",
       "\n",
       "       Intl Calls  Intl Charge  CustServ Calls  Churn?  \n",
       "State                                                   \n",
       "PA              6     5.673203               3   True.  \n",
       "SC              6     2.559749               8  False.  \n",
       "MO              2     6.254157               4  False.  \n",
       "WY              6     1.080692               6  False.  \n",
       "WY              4     7.134343               6   True.  \n",
       "...           ...          ...             ...     ...  \n",
       "NH              8     2.122530               9  False.  \n",
       "SD              2     4.600473               4  False.  \n",
       "SC              7     1.060340               6  False.  \n",
       "MA              3     4.871900               7   True.  \n",
       "AL              6     5.485345               7  False.  \n",
       "\n",
       "[5000 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pd.read_csv(\"../dataset/churn.txt\", index_col=0)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modern standards, it’s a relatively small dataset, with only 5,000 records, where each record uses 21 attributes to describe the profile of a customer of an unknown US mobile operator. The attributes are:\n",
    "\n",
    "- `State`: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n",
    "- `Account Length`: the number of days that this account has been active\n",
    "- `Area Code`: the three-digit area code of the corresponding customer’s phone number\n",
    "- `Phone`: the remaining seven-digit phone number\n",
    "- `Int’l Plan`: whether the customer has an international calling plan: yes/no\n",
    "- `VMail Plan`: whether the customer has a voice mail feature: yes/no\n",
    "- `VMail Message`: presumably the average number of voice mail messages per month\n",
    "- `Day Mins`: the total number of calling minutes used during the day\n",
    "- `Day Calls`: the total number of calls placed during the day\n",
    "- `Day Charge`: the billed cost of daytime calls\n",
    "- `Eve Mins, Eve Calls, Eve Charge`: the billed cost for calls placed during the evening\n",
    "- `Night Mins`, `Night Calls`, `Night Charge`: the billed cost for calls placed during nighttime\n",
    "- `Intl Mins`, `Intl Calls`, `Intl Charge`: the billed cost for international calls\n",
    "- `CustServ Calls`: the number of calls placed to Customer Service\n",
    "- `Churn?`: whether the customer left the service: true/false\n",
    "\n",
    "The last attribute, `Churn?`, is known as the target attribute–the attribute that we want the ML model to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing some columns that might skew our model\n",
    "\n",
    "We are going to drop the Area Code and Phone as they might skew our model. The reason we do this here is that a customer may have a mobile phone and so their area code of their number may lead to misleading assumptions. We are going to drop these columns here to keep the dataset consistent for this lab and the auto-sklearn lab to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn.drop(columns=['Area Code', 'Phone'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reserve some data for calling inference on the model\n",
    "\n",
    "Divide the data into training and testing splits. The training split is used by SageMaker Autopilot. The testing split is reserved to perform inference using the suggested model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = churn.sample(frac=0.8, random_state=200)\n",
    "\n",
    "test_data = churn.drop(train_data.index)\n",
    "\n",
    "test_data_no_target = test_data.drop(columns=[\"Churn?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3. We are also going to save a test data file to S3 which includes the target which we will use when testing in our auto-sklearn excercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data uploaded to: s3://sagemaker-us-east-1-650687152614/sagemaker/autopilot-cust-churn/train/train_data.csv\n",
      "Test data uploaded to: s3://sagemaker-us-east-1-650687152614/sagemaker/autopilot-cust-churn/test/test_data.csv\n",
      "Test data with target uploaded to: s3://sagemaker-us-east-1-650687152614/sagemaker/autopilot-cust-churn/test/test_data_w_target.csv\n"
     ]
    }
   ],
   "source": [
    "train_file = \"train_data.csv\"\n",
    "train_data.to_csv(train_file, index=False, header=True)\n",
    "train_data_s3_path = session.upload_data(path=train_file, key_prefix=prefix + \"/train\")\n",
    "print(\"Train data uploaded to: \" + train_data_s3_path)\n",
    "\n",
    "test_file = \"test_data.csv\"\n",
    "test_data_no_target.to_csv(test_file, index=False, header=False)\n",
    "test_data_s3_path = session.upload_data(path=test_file, key_prefix=prefix + \"/test\")\n",
    "print(\"Test data uploaded to: \" + test_data_s3_path)\n",
    "\n",
    "test_file_wt = \"test_data_w_target.csv\"\n",
    "test_data.to_csv(test_file_wt, index=False, header=True)\n",
    "test_data_s3_path = session.upload_data(path=test_file_wt, key_prefix=prefix + \"/test\")\n",
    "print(\"Test data with target uploaded to: \" + test_data_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setting up the SageMaker Autopilot Job<a name=\"Settingup\"></a>\n",
    "\n",
    "After uploading the dataset to Amazon S3, you can invoke Autopilot to find the best ML pipeline to train a model on this dataset. \n",
    "\n",
    "The required inputs for invoking a Autopilot job are:\n",
    "* Amazon S3 location for input dataset and for all output artifacts\n",
    "* Name of the column of the dataset you want to predict (`Churn?` in this case) \n",
    "* An IAM role\n",
    "\n",
    "Currently Autopilot supports only tabular datasets in CSV format. Either all files should have a header row, or the first file of the dataset, when sorted in alphabetical/lexical order by name, is expected to have a header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_config = [\n",
    "    {\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": \"s3://{}/{}/train\".format(bucket, prefix),\n",
    "            }\n",
    "        },\n",
    "        \"TargetAttributeName\": \"Churn?\",\n",
    "    }\n",
    "]\n",
    "\n",
    "output_data_config = {\"S3OutputPath\": \"s3://{}/{}/output\".format(bucket, prefix)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify the type of problem you want to solve with your dataset (`Regression, MulticlassClassification, BinaryClassification`). In case you are not sure, SageMaker Autopilot will infer the problem type based on statistics of the target column (the column you want to predict). \n",
    "\n",
    "Because the target attribute, ```Churn?```, is binary, our model will be performing binary prediction, also known as binary classification. In this example we will let AutoPilot infer the type of problem for us.\n",
    "\n",
    "You have the option to limit the running time of a SageMaker Autopilot job by providing either the maximum number of pipeline evaluations or candidates (one pipeline evaluation is called a `Candidate` because it generates a candidate model) or providing the total time allocated for the overall Autopilot job. Under default settings, this job takes about four hours to run. This varies between runs because of the nature of the exploratory process Autopilot uses to find optimal training parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching the SageMaker Autopilot Job<a name=\"Launching\"></a>\n",
    "\n",
    "You can now launch the Autopilot job by calling the `create_auto_ml_job` API. We limit the number of candidates to 20 so that the job finishes in a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLJobName: automl-churn-14-01-08-58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AutoMLJobArn': 'arn:aws:sagemaker:us-east-1:650687152614:automl-job/automl-churn-14-01-08-58',\n",
       " 'ResponseMetadata': {'RequestId': 'a92649a8-f912-4109-9ee7-1d5f4e00c9a8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a92649a8-f912-4109-9ee7-1d5f4e00c9a8',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '95',\n",
       "   'date': 'Tue, 14 Sep 2021 01:08:59 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "timestamp_suffix = strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "auto_ml_job_name = \"automl-churn-\" + timestamp_suffix\n",
    "print(\"AutoMLJobName: \" + auto_ml_job_name)\n",
    "\n",
    "sm.create_auto_ml_job(\n",
    "    AutoMLJobName=auto_ml_job_name,\n",
    "    InputDataConfig=input_data_config,\n",
    "    OutputDataConfig=output_data_config,\n",
    "    AutoMLJobConfig={\"CompletionCriteria\": {\"MaxCandidates\": 20, \"MaxRuntimePerTrainingJobInSeconds\": 30}},\n",
    "    RoleArn=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'auto_ml_job_name' (str)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'automl-churn-14-01-08-58'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the AutoMLJobName name for use in subsequent notebooks\n",
    "%store auto_ml_job_name\n",
    "auto_ml_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking SageMaker Autopilot job progress<a name=\"Tracking\"></a>\n",
    "SageMaker Autopilot job consists of the following high-level steps : \n",
    "* Analyzing Data, where the dataset is analyzed and Autopilot comes up with a list of ML pipelines that should be tried out on the dataset. The dataset is also split into train and validation sets.\n",
    "* Feature Engineering, where Autopilot performs feature transformation on individual features of the dataset as well as at an aggregate level.\n",
    "* Model Tuning, where the top performing pipeline is selected along with the optimal hyperparameters for the training algorithm (the last stage of the pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus - Secondary Status\n",
      "------------------------------\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - AnalyzingData\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - FeatureEngineering\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "InProgress - ModelTuning\n",
      "Failed - Failed\n",
      "CPU times: user 512 ms, sys: 63.2 ms, total: 575 ms\n",
      "Wall time: 24min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"JobStatus - Secondary Status\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "\n",
    "describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "print(describe_response[\"AutoMLJobStatus\"] + \" - \" + describe_response[\"AutoMLJobSecondaryStatus\"])\n",
    "job_run_status = describe_response[\"AutoMLJobStatus\"]\n",
    "\n",
    "while job_run_status not in (\"Failed\", \"Completed\", \"Stopped\"):\n",
    "    describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "    job_run_status = describe_response[\"AutoMLJobStatus\"]\n",
    "\n",
    "    print(\n",
    "        describe_response[\"AutoMLJobStatus\"] + \" - \" + describe_response[\"AutoMLJobSecondaryStatus\"]\n",
    "    )\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AutoPilot automatically generates two executable Jupyter Notebooks:  <br> - SageMakerAutopilotDataExplorationNotebook.ipynb <br> and <br> - SageMakerAutopilotCandidateDefinitionNotebook.ipynb. <br> These notebooks are stored in S3. Let us download them onto our SageMaker Notebook instance so we could explore them later.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-650687152614/sagemaker/DEMO-autopilot-churn/output/automl-churn-12-19-41-50/sagemaker-automl-candidates/automl-churn-12-19-41-50-pr-1-863b5602544b4e56a4546ae22f5c3f9c0/notebooks/SageMakerAutopilotCandidateDefinitionNotebook.ipynb\n",
      "s3://sagemaker-us-east-1-650687152614/sagemaker/DEMO-autopilot-churn/output/automl-churn-12-19-41-50/sagemaker-automl-candidates/automl-churn-12-19-41-50-pr-1-863b5602544b4e56a4546ae22f5c3f9c0/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "# print(describe_response)\n",
    "print(describe_response[\"AutoMLJobArtifacts\"][\"CandidateDefinitionNotebookLocation\"])\n",
    "print(describe_response[\"AutoMLJobArtifacts\"][\"DataExplorationNotebookLocation\"])\n",
    "\n",
    "candidate_nbk = describe_response[\"AutoMLJobArtifacts\"][\"CandidateDefinitionNotebookLocation\"]\n",
    "data_explore_nbk = describe_response[\"AutoMLJobArtifacts\"][\"DataExplorationNotebookLocation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-650687152614 sagemaker/DEMO-autopilot-churn/output/automl-churn-12-19-41-50/sagemaker-automl-candidates/automl-churn-12-19-41-50-pr-1-863b5602544b4e56a4546ae22f5c3f9c0/notebooks/SageMakerAutopilotCandidateDefinitionNotebook.ipynb sagemaker/DEMO-autopilot-churn/output/automl-churn-12-19-41-50/sagemaker-automl-candidates/automl-churn-12-19-41-50-pr-1-863b5602544b4e56a4546ae22f5c3f9c0/notebooks/SageMakerAutopilotDataExplorationNotebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "def split_s3_path(s3_path):\n",
    "    path_parts = s3_path.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = path_parts.pop(0)\n",
    "    key = \"/\".join(path_parts)\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "s3_bucket, candidate_nbk_key = split_s3_path(candidate_nbk)\n",
    "_, data_explore_nbk_key = split_s3_path(data_explore_nbk)\n",
    "\n",
    "print(s3_bucket, candidate_nbk_key, data_explore_nbk_key)\n",
    "\n",
    "session.download_data(path=\"./\", bucket=s3_bucket, key_prefix=candidate_nbk_key)\n",
    "\n",
    "session.download_data(path=\"./\", bucket=s3_bucket, key_prefix=data_explore_nbk_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "---\n",
    "## Results\n",
    "\n",
    "Now use the describe_auto_ml_job API to look up the best candidate selected by the SageMaker Autopilot job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BestCandidate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-73dce4046eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_candidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_auto_ml_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoMLJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_ml_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BestCandidate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_candidate_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_candidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CandidateName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_candidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CandidateName: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbest_candidate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BestCandidate'"
     ]
    }
   ],
   "source": [
    "best_candidate = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)[\"BestCandidate\"]\n",
    "best_candidate_name = best_candidate[\"CandidateName\"]\n",
    "print(best_candidate)\n",
    "print(\"\\n\")\n",
    "print(\"CandidateName: \" + best_candidate_name)\n",
    "print(\n",
    "    \"FinalAutoMLJobObjectiveMetricName: \"\n",
    "    + best_candidate[\"FinalAutoMLJobObjectiveMetric\"][\"MetricName\"]\n",
    ")\n",
    "print(\n",
    "    \"FinalAutoMLJobObjectiveMetricValue: \"\n",
    "    + str(best_candidate[\"FinalAutoMLJobObjectiveMetric\"][\"Value\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to some randomness in the algorithms involved, different runs will provide slightly different results, but accuracy will be around or above $93\\%$, which is a good result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you are curious to explore the performance of other algorithms that AutoPilot explored, they are enumerated for you below via list_candidates_for_auto_ml_job() API call**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "# sm.list_auto_ml_jobs()\n",
    "sm_dict = sm.list_candidates_for_auto_ml_job(AutoMLJobName=auto_ml_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sm_dict[\"Candidates\"]:\n",
    "    try:\n",
    "        print(item[\"CandidateName\"], item[\"FinalAutoMLJobObjectiveMetric\"])\n",
    "        print(item[\"InferenceContainers\"][1][\"Image\"], \"\\n\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Host\n",
    "\n",
    "Now that we've trained the algorithm, let's create a model and deploy it to a hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_suffix = strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "model_name = best_candidate_name + timestamp_suffix + \"-model\"\n",
    "model_arn = sm.create_model(\n",
    "    Containers=best_candidate[\"InferenceContainers\"], ModelName=model_name, ExecutionRoleArn=role\n",
    ")\n",
    "\n",
    "epc_name = best_candidate_name + timestamp_suffix + \"-epc\"\n",
    "ep_config = sm.create_endpoint_config(\n",
    "    EndpointConfigName=epc_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m5.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"main\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "ep_name = best_candidate_name + timestamp_suffix + \"-ep\"\n",
    "create_endpoint_response = sm.create_endpoint(EndpointName=ep_name, EndpointConfigName=epc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.get_waiter(\"endpoint_in_service\").wait(EndpointName=ep_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "Now that we have a hosted endpoint running, we can make real-time predictions from our model very easily, simply by making an http POST request.  But first, we'll need to setup serializers and deserializers for passing our `test_data` NumPy arrays to the model behind the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "if sagemaker.__version__ < \"2\":\n",
    "    from sagemaker.predictor import RealTimePredictor\n",
    "    from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "    predictor = RealTimePredictor(\n",
    "        endpoint=ep_name,\n",
    "        sagemaker_session=session,\n",
    "        content_type=CONTENT_TYPE_CSV,\n",
    "        accept=CONTENT_TYPE_CSV,\n",
    "    )\n",
    "\n",
    "    # Remove the target column from the test data\n",
    "    test_data_inference = test_data.drop(\"Churn?\", axis=1)\n",
    "\n",
    "    # Obtain predictions from SageMaker endpoint\n",
    "    prediction = predictor.predict(\n",
    "        test_data_inference.to_csv(sep=\",\", header=False, index=False)\n",
    "    ).decode(\"utf-8\")\n",
    "\n",
    "    # Load prediction in pandas and compare to ground truth\n",
    "    prediction_df = pd.read_csv(StringIO(prediction), header=None)\n",
    "    accuracy = (test_data.reset_index()[\"Churn?\"] == prediction_df[0]).sum() / len(\n",
    "        test_data_inference\n",
    "    )\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "else:\n",
    "    from sagemaker.predictor import Predictor\n",
    "    from sagemaker.serializers import CSVSerializer\n",
    "    from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "    predictor = Predictor(\n",
    "        endpoint_name=ep_name,\n",
    "        sagemaker_session=session,\n",
    "        serializer=CSVSerializer(),\n",
    "        deserializer=CSVDeserializer(),\n",
    "    )\n",
    "\n",
    "    # Remove the target column from the test data\n",
    "    test_data_inference = test_data.drop(\"Churn?\", axis=1)\n",
    "\n",
    "    # Obtain predictions from SageMaker endpoint\n",
    "    prediction = predictor.predict(test_data_inference.to_csv(sep=\",\", header=False, index=False))\n",
    "\n",
    "    # Load prediction in pandas and compare to ground truth\n",
    "    prediction_df = pd.DataFrame(prediction)\n",
    "    accuracy = (test_data.reset_index()[\"Churn?\"] == prediction_df[0]).sum() / len(\n",
    "        test_data_inference\n",
    "    )\n",
    "    print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(test_data.reset_index()[\"Churn?\"], prediction_df[0])\n",
    "precision = precision_score(test_data.reset_index()[\"Churn?\"], prediction_df[0], pos_label=\"True.\")\n",
    "recall = recall_score(\n",
    "    test_data.reset_index()[\"Churn?\"], prediction_df[0], pos_label=\"True.\", average=\"binary\"\n",
    ")\n",
    "f1 = f1_score(test_data.reset_index()[\"Churn?\"], prediction_df[0], pos_label=\"True.\")\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "print(\"Precision: {}\".format(precision))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "print(\"F1: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "totaltime = t1-t0\n",
    "print(f\"Total Time {totaltime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Cleanup\n",
    "\n",
    "The Autopilot job creates many underlying artifacts such as dataset splits, preprocessing scripts, or preprocessed data, etc. This code, when un-commented, deletes them. This operation deletes all the generated models and the auto-generated notebooks as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3_bucket = s3.Bucket(bucket)\n",
    "\n",
    "print(s3_bucket)\n",
    "job_outputs_prefix = '{}/output/{}'.format(prefix, auto_ml_job_name)\n",
    "print(job_outputs_prefix)\n",
    "#s3_bucket.objects.filter(Prefix=job_outputs_prefix).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we delete the endpoint and associated resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=ep_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=epc_name)\n",
    "sm.delete_model(ModelName=model_name)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
